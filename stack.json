{
  "id": "[stack]bigboards$bb-stack-spark-on-hadoop",
  "views": [
    {
      "label": "Yarn",
      "url": "http://{{ nodes[hex.name + '-n1'].ip }}:8088/",
      "description": "The Yarn Web Console. It allows you to master the applications running within Yarn."
    },
    {
      "label": "HDFS",
      "url": "http://{{ nodes[hex.name + '-n1'].ip }}:50070/",
      "description": "The Web Console for the HDFS NameNode. It gives you more details about the data stored on the cluster"
    },
    {
      "label": "WebUI",
      "url": "http://{{ nodes[hex.name + '-n1'].ip }}:8070/",
      "description": "The Spark Web UI"
    },
    {
      "label": "Jupyter Hub",
      "url": "http://{{ nodes[hex.name + '-n1'].ip }}:8000/",
      "description": "The Notebook hub"
    }
  ],
  "containers": [
    {
      "name": "jupyterhub",
      "image": "bigboards/pyspark",
      "command": "jupyterhub -f /srv/jupyterhub/jupyterhub_config.py",
      "ports": [
        8000
      ],
      "config": {
        "host_path": "jupyterhub",
        "container_path": "/tmp/jupyterhub"
      },
      "pre_install": "scripts/fs_permissions.yml"
    },
    {
      "name": "namenode",
      "image": "bigboards/hadoop",
      "command": "/opt/hadoop/bin/hdfs-namenode-wrapper.sh",
      "ports": [
        8020,
        50070,
        50470
      ],
      "config": {
        "host_path": "namenode",
        "container_path": "/opt/hadoop/etc/hadoop"
      },
      "pre_install": "scripts/namenode/pre_install.yml"
    },
    {
      "name": "datanode",
      "image": "bigboards/hadoop",
      "command": "/opt/hadoop/bin/hdfs --config /opt/hadoop/etc/hadoop datanode",
      "ports": [
        1004,
        1006,
        50010,
        50020,
        50075
      ],
      "config": {
        "host_path": "datanode",
        "container_path": "/opt/hadoop/etc/hadoop"
      }
    },
    {
      "name": "resourcemanager",
      "image": "bigboards/hadoop",
      "command": "/opt/hadoop/bin/yarn --config /opt/hadoop/etc/hadoop resourcemanager",
      "ports": [
        8030,
        8031,
        8032,
        8033,
        8088
      ],
      "config": {
        "host_path": "resourcemanager",
        "container_path": "/opt/hadoop/etc/hadoop"
      }
    },
    {
      "name": "nodemanager",
      "image": "bigboards/hadoop",
      "command": "/opt/hadoop/bin/yarn --config /opt/hadoop/etc/hadoop nodemanager",
      "ports": [
        8040,
        8041,
        8042
      ],
      "config": {
        "host_path": "nodemanager",
        "container_path": "/opt/hadoop/etc/hadoop"
      }
    },
    {
      "name": "proxyserver",
      "image": "bigboards/hadoop",
      "command": "/opt/hadoop/bin/yarn --config /opt/hadoop/etc/hadoop proxyserver",
      "ports": [
        8080
      ],
      "config": {
        "host_path": "proxyserver",
        "container_path": "/opt/hadoop/etc/hadoop"
      }
    },
    {
      "name": "historyserver",
      "image": "bigboards/hadoop",
      "command": "/opt/hadoop/bin/yarn --config /opt/hadoop/etc/hadoop historyserver",
      "ports": [
        10020,
        19888
      ],
      "config": {
        "host_path": "historyserver",
        "container_path": "/opt/hadoop/etc/hadoop"
      }
    },
    {
      "name": "spark_master",
      "image": "bigboards/spark",
      "command": "/opt/spark/bin/spark-class org.apache.spark.deploy.master.Master --port 7077 --webui-port 8070 -h {{ hex.name }}-n1.hex",
      "ports": [
        7077,
        8070
      ],
      "config": {
        "host_path": "spark_master",
        "container_path": "/opt/spark/conf"
      }
    },
    {
      "name": "spark_worker",
      "image": "bigboards/spark",
      "command": "/opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://{{ hex.name }}-n1.hex:7077 -d /data",
      "ports": [
        7078,
        8081
      ],
      "config": {
        "host_path": "spark_worker",
        "container_path": "/opt/spark/conf"
      }
    }
  ],
  "groups": [
    {
      "name": "hadoop_masters",
      "runs_on": "host-coordinators",
      "containers": [
        "namenode",
        "resourcemanager",
        "proxyserver",
        "historyserver"
      ]
    },
    {
      "name": "hadoop_slaves",
      "runs_on": "host-workers",
      "containers": [
        "datanode",
        "nodemanager"
      ]
    },
    {
      "name": "spark_master",
      "runs_on": "host-coordinators",
      "containers": ["spark_master"]
    },
    {
      "name": "frontends",
      "runs_on": "host-coordinators",
      "containers": ["jupyterhub"]
    }
  ]
}