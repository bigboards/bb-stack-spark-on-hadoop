{
  "id": "[stack]bigboards$bb-stack-elasticsearch-shield",
  "slug": "bb-stack-spark-on-hadoop",
  "name": "Apache Spark on Apache Hadoop",
  "description": "EXPERIMENTAL - things might break!!! Apache Sparkâ„¢ is a fast and general engine for large-scale data processing, which is here deployed on Apache Hadoop for distributed storage and resource management.",
  "type": "stack",
  "owner": "bigboards",
  "logo": "https://bitbucket-assetroot.s3.amazonaws.com/c/photos/2015/Feb/18/3592780503-2-bb-stack-spark-logo_avatar.png",
  "type": "stack",
  "architecture": "armv7l",
  "supported_firmwares": ["feniks", "ember", "feniks-wip"],
  "uri": "https://bitbucket.org/bigboards/bb-stack-spark-on-hadoop",
  "stack": {
    "views": [
      {
        "label": "Yarn",
        "url": "http://{{ nodes[hex.name + '-n1'].ip }}:8088/",
        "description": "The Yarn Web Console. It allows you to master the applications running within Yarn."
      },
      {
        "label": "HDFS",
        "url": "http://{{ nodes[hex.name + '-n1'].ip }}:50070/",
        "description": "The Web Console for the HDFS NameNode. It gives you more details about the data stored on the cluster"
      },
      {
        "label": "WebUI",
        "url": "http://{{ nodes[hex.name + '-n1'].ip }}:8070/",
        "description": "The Spark Web UI"
      }
    ],
    "containers": [
      {
        "name": "namenode",
        "image": "bigboards/hadoop-armv7l",
        "command": "/opt/hadoop/bin/hdfs-namenode-wrapper.sh",
        "ports": [
          8020,
          50070,
          50470
        ],
        "config": {
          "host_path": "namenode",
          "container_path": "/opt/hadoop/etc/hadoop"
        },
        "pre_install": "scripts/namenode/pre_install.yml"
      },
      {
        "name": "datanode",
        "image": "bigboards/hadoop-armv7l",
        "command": "/opt/hadoop/bin/hdfs --config /opt/hadoop/etc/hadoop datanode",
        "ports": [
          1004,
          1006,
          50010,
          50020,
          50075
        ],
        "config": {
          "host_path": "datanode",
          "container_path": "/opt/hadoop/etc/hadoop"
        }
      },
      {
        "name": "resourcemanager",
        "image": "bigboards/hadoop-armv7l",
        "command": "/opt/hadoop/bin/yarn --config /opt/hadoop/etc/hadoop resourcemanager",
        "ports": [
          8030,
          8031,
          8032,
          8033,
          8088
        ],
        "config": {
          "host_path": "resourcemanager",
          "container_path": "/opt/hadoop/etc/hadoop"
        }
      },
      {
        "name": "nodemanager",
        "image": "bigboards/hadoop-armv7l",
        "command": "/opt/hadoop/bin/yarn --config /opt/hadoop/etc/hadoop nodemanager",
        "ports": [
          8040,
          8041,
          8042
        ],
        "config": {
          "host_path": "nodemanager",
          "container_path": "/opt/hadoop/etc/hadoop"
        }
      },
      {
        "name": "proxyserver",
        "image": "bigboards/hadoop-armv7l",
        "command": "/opt/hadoop/bin/yarn --config /opt/hadoop/etc/hadoop proxyserver",
        "ports": [
          8080
        ],
        "config": {
          "host_path": "proxyserver",
          "container_path": "/opt/hadoop/etc/hadoop"
        }
      },
      {
        "name": "historyserver",
        "image": "bigboards/hadoop-armv7l",
        "command": "/opt/hadoop/bin/yarn --config /opt/hadoop/etc/hadoop historyserver",
        "ports": [
          10020,
          19888
        ],
        "config": {
          "host_path": "historyserver",
          "container_path": "/opt/hadoop/etc/hadoop"
        }
      },
      {
        "name": "spark_master",
        "image": "bigboards/spark-armv7l",
        "command": "/opt/spark/bin/spark-class org.apache.spark.deploy.master.Master --port 7077 --webui-port 8070 -h {{ hex.name }}-n1.hex",
        "ports": [
          7077,
          8070
        ],
        "config": {
          "host_path": "all",
          "container_path": "/opt/spark/conf"
        }
      },
      {
        "name": "spark_worker",
        "image": "bigboards/spark-armv7l",
        "command": "/opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://{{ hex.name }}-n1.hex:7077 -d /data",
        "ports": [
          7078,
          8081
        ],
        "config": {
          "host_path": "all",
          "container_path": "/opt/spark/conf"
        }
      }
    ],
    "groups": [
      {
        "name": "hadoop_masters",
        "runs_on": "n1",
        "containers": [
          "namenode",
          "resourcemanager",
          "proxyserver",
          "historyserver"
        ]
      },
      {
        "name": "hadoop_slaves",
        "runs_on": "all:!n1",
        "containers": [
          "datanode",
          "nodemanager"
        ]
      },
      {
        "name": "spark_master",
        "runs_on": "n1",
        "containers": [
          "spark_master"
        ]
      }
    ]
  }
}